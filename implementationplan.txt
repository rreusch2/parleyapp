This is an exciting stage for Predictive Play! Moving forward with the LLM Orchestrator strategy is smart. It aligns perfectly with your current progress (UI, Auth, Sports-API integration) and gets you to an intelligent app quickly.

Here's a comprehensive implementation plan for the LLM Orchestrator strategy, followed by a detailed prompt for your coding AI.

Predictive Play: LLM Orchestrator Implementation Plan
Goal: Implement a sophisticated AI prediction system using an LLM (Gemini) as an orchestrator, leveraging multiple external prediction APIs and tools to provide personalized, explained sports betting and player prop picks.

Current Status:

React Native App: Basic UI, Login/Signup, Authentication (Supabase).
Node.js Backend: Express.js, TypeScript, Supabase for DB/Auth.
Data Integration: Sports-API integrated to fetch and store upcoming/live games. Basic UI for games page is working.
Core Strategy: LLM (Gemini) as the intelligent agent, calling specialized tools (external prediction APIs, odds APIs, web search, internal user data) to generate personalized and explained betting picks.

Phase 1: Foundational Backend & Tooling (Weeks 1-3)
Objective: Establish the communication layer between your Node.js backend and external APIs, and define the tools the LLM will use.

Select & Integrate External Prediction APIs (Initial Tooling):

Action: Research and sign up for 2-3 top-tier prediction APIs. Prioritize those with clear documentation, good coverage for your target sports, and a free tier/trial for development.
Recommendation:
SportsDataIO (BAKER Engine): Strong for US sports, offers probabilities, EV, ROI. Good for general game predictions.
Sportradar Probabilities API: A global leader, reliable probabilities for many sports.
Sportmonks (Prediction Add-on): Excellent for Football (Soccer) if that's a primary focus.
Backend Implementation:
Create separate Node.js/TypeScript modules/services (e.g., src/services/sportsdataio.ts, src/services/sportradar.ts) to encapsulate API calls.
Implement robust error handling, retry mechanisms, and rate limit management for each API.
Define functions within these modules that will serve as "tools" for the LLM (e.g., sportsDataIOPredictions.getGamePrediction(gameId, betType), sportradar.getProbabilities(gameId)).
Integrate Odds API:

Action: Select and integrate a dedicated Odds API (e.g., The Odds API).
Backend Implementation: Create src/services/oddsapi.ts with a tool function oddsApi.getCurrentOdds(gameId, market). This is crucial for identifying value.
Implement Web Search Tool:

Action: Choose a programmatic web search API (e.g., Google Custom Search API, SerpApi, or a basic node-fetch and a parsing library for a simple scrape if budget is very tight, but be mindful of TOS).
Backend Implementation: Create src/services/webSearch.ts with a tool function webSearch.search(query). This will allow the LLM to fetch real-time news, injury updates, etc.
Supabase User Data Tool:

Action: Define how the LLM can access user-specific data from Supabase.
Backend Implementation: Create src/services/userData.ts with a tool function userData.getUserPreferences(userId) and userData.getBettingHistory(userId). This ensures personalization.
Phase 2: LLM Integration & Orchestration (Weeks 4-6)
Objective: Connect your backend to Gemini, define the system prompt, and establish the core prediction flow.

Gemini API Integration:

Action: Get Gemini API credentials from Google Cloud.
Backend Implementation:
Install the official Google Generative AI Node.js client library (@google/generative-ai).
Create a dedicated src/services/gemini.ts module.
Implement a core function (e.g., gemini.orchestratePrediction(userId, userQuery, gameId)).
This function will dynamically construct the prompt for Gemini, including the tool definitions (see prompt below).
Develop Core LLM System Prompt:

Action: Craft the comprehensive prompt that defines Gemini's role, objectives, decision-making process, and output format.
Backend Implementation: Store this prompt string in your backend (e.g., as a constant or fetched from config) and inject dynamic user/game data. (See detailed prompt below).
Prediction API Endpoint:

Action: Create a new API endpoint in your Express.js backend (e.g., POST /api/predictions) that your React Native app will call.
Backend Implementation:
This endpoint will receive user requests (e.g., userId, gameId, betTypePreference).
It will then call your gemini.orchestratePrediction function.
Handle streaming responses from Gemini if applicable, or send the final parsed pick back to the frontend.
Logging & Monitoring:

Action: Implement robust logging for all LLM interactions, tool calls, and responses. This is critical for debugging, cost tracking, and future model evaluation.
Backend Implementation: Use a logging library (e.g., Winston) to log to files or a dedicated logging service.
Phase 3: Frontend Integration & User Experience (Weeks 7-9)
Objective: Display AI-powered picks and explanations in the React Native app.

Predictions UI Component:

Action: Design and build a new React Native component to display the AI's picks.
Frontend Implementation:
Display the recommended bet, odds, rationale, and confidence level.
Allow users to trigger a prediction for a specific game/bet type.
Handle loading states and error messages gracefully.
User Preferences Input (Optional but Recommended):

Action: Create a UI in the app where users can set their risk tolerance, favorite teams/players, etc.
Frontend & Backend Implementation: Store these preferences in Supabase and ensure your userData.getUserPreferences tool can retrieve them for the LLM.
Feedback Mechanism:

Action: Implement a simple "thumbs up/down" or short survey for users to provide feedback on picks.
Frontend & Backend Implementation: Store this feedback in Supabase. This data is invaluable for refining your LLM prompt and future custom ML models.
Phase 4: Optimization, Evaluation & Iteration (Ongoing)
Objective: Continuously improve the AI's performance and profitability.

Prompt Refinement:

Action: Based on logged LLM interactions and user feedback, continually refine your Gemini system prompt to improve prediction quality, explanation clarity, and adherence to user preferences.
Team: This will be a collaborative effort between developers and potentially someone with sports betting domain knowledge.
Performance Tracking:

Action: Develop a system to track the actual outcomes of games/props against the AI's predictions and the associated odds.
Backend & Supabase: Store actual results and calculate profitability (ROI, EV) for each pick over time.
Internal Dashboard: Create a simple internal dashboard to visualize performance.
Tool Improvement:

Action: Explore adding more sophisticated tools (e.g., an internal calculator tool for the LLM to perform specific statistical operations, a tool to query your own Supabase data directly for historical context if needed).
Action: Monitor API costs and performance. Consider switching providers if needed.
Future Custom ML Integration (As discussed earlier):

Action: Begin the process of building your own data pipelines, feature engineering, and custom ML models for specific, high-value prediction tasks (especially player props).
Integration: Once mature, these custom models will become new, powerful "tools" for your LLM orchestrator.
Coding AI Prompt: Predictive Play AI System Implementation
Here's the prompt you can give to your coding AI. I've broken it down into sections to make it clear and actionable for an AI.

Prompt for Coding AI: Predictive Play - LLM Orchestrator System Implementation

Project Name: Predictive Play
App Type: React Native (Frontend) + Node.js/Express.js/TypeScript (Backend)
Database/Auth: Supabase
Current Progress: Basic UI, User Authentication (login/signup working), Games Page fetching and displaying upcoming/live games from Sports-API.

Objective: Implement the "LLM Orchestrator" AI system for Predictive Play. The core idea is that a large language model (LLM), specifically Google's Gemini, will act as an intelligent agent. It will orchestrate calls to various external "tools" (APIs) to generate personalized and explained sports betting and player prop picks for the user.

Target Output:

Backend Code Structure: Organized Node.js/TypeScript files for services, routes, and LLM integration.
Key Service Implementations: Code for integrating with external APIs as LLM tools.
Express.js API Endpoint: A robust endpoint for the React Native app to request predictions.
Gemini System Prompt: A detailed, effective prompt string for the LLM.
High-Level Frontend Integration Strategy: How the React Native app will interact with the new backend endpoint.
Supabase Schema Suggestions: Any new tables or columns needed.
Detailed Plan for Coding AI:

1. Backend Core Setup:

Project Structure: Assume an existing Node.js/Express.js/TypeScript project. Organize new AI-related files under a new src/ai/ directory, with subdirectories like src/ai/tools/ and src/ai/orchestrator/.
Dependency Management: Suggest relevant npm packages (e.g., @google/generative-ai, axios, etc.).
2. Implement External API "Tools" (Backend - src/ai/tools/):

For each of the following, create a dedicated TypeScript file (.ts) that encapsulates the API calls. These files should export functions that will be callable by the LLM through the @google/generative-ai client's tool definition. Include placeholder API keys/URLs (e.g., process.env.SPORTSDATAIO_API_KEY).

* **2.1. SportsDataIO (BAKER Engine) Integration:**
    * **File:** `src/ai/tools/sportsDataIO.ts`
    * **Functions:**
        * `getGamePrediction(gameId: string, betType: 'moneyline' | 'spread' | 'total', sport: string)`: Fetches game outcome predictions/probabilities.
        * `getPlayerPropPrediction(playerId: string, gameId: string, statType: string, overUnderLine: number, sport: string)`: Fetches player prop predictions.
    * **Description:** Tool for accessing pre-calculated probabilities and potential "best bets" from SportsDataIO's predictive engine.

* **2.2. Sportradar Probabilities API Integration:**
    * **File:** `src/ai/tools/sportradar.ts`
    * **Functions:**
        * `getMatchProbabilities(gameId: string, sport: string)`: Fetches 3-way (win/draw/lose) probabilities.
    * **Description:** Tool for accessing general game outcome probabilities from Sportradar.

* **2.3. The Odds API Integration:**
    * **File:** `src/ai/tools/oddsApi.ts`
    * **Functions:**
        * `getLatestOdds(gameId: string, sport: string, marketType: 'moneyline' | 'spread' | 'total', bookmakers?: string[])`: Fetches current odds from multiple bookmakers.
    * **Description:** Tool for fetching real-time betting odds to identify value.

* **2.4. Web Search Integration:**
    * **File:** `src/ai/tools/webSearch.ts`
    * **Functions:**
        * `performSearch(query: string)`: Executes a web search.
    * **Description:** Tool for gathering qualitative information like injury reports, news, recent team buzz. Suggest using a simple `node-fetch` to a search proxy if no dedicated API is available, or recommend a specific search API like Google Custom Search.

* **2.5. Supabase User Data Tool:**
    * **File:** `src/ai/tools/userData.ts`
    * **Functions:**
        * `getUserPreferences(userId: string)`: Fetches user-defined preferences (e.g., risk tolerance, favorite teams/players, preferred bet types).
        * `getUserBettingHistory(userId: string, limit: number)`: Fetches recent betting history.
    * **Description:** Tool for providing personalized context to the LLM.
3. LLM Orchestrator Implementation (Backend - src/ai/orchestrator/):

File: src/ai/orchestrator/geminiOrchestrator.ts
Main Function: generatePrediction(userId: string, gameId: string, userQuery: string)
This function will:
Initialize the Gemini model with the defined system prompt and the list of available tools.
Start a chat session with Gemini.
Pass the userQuery (from the React Native app) as the initial message.
Handle tool calls: When Gemini requests to use a tool, execute the corresponding function from src/ai/tools/ and return the result to Gemini.
Handle Gemini's final response: Parse the structured output from Gemini.
Implement basic error handling for Gemini API calls and tool execution.
4. Express.js API Endpoint (Backend - src/routes/ or similar):

File: src/routes/predictionRoutes.ts
Endpoint: POST /api/predict
Authentication: Ensure this endpoint is protected by your existing Supabase authentication.
Request Body: Expect userId, gameId, and userQuery (e.g., "Give me a pick for the Lakers vs. Celtics game," or "Suggest a player prop for LeBron James").
Logic: Call geminiOrchestrator.generatePrediction with the received parameters.
Response: Return the LLM's parsed prediction output to the frontend (e.g., a JSON object containing the recommended bet, rationale, confidence, etc.).
5. Gemini System Prompt (for geminiOrchestrator.ts):

Provide a detailed system prompt for Gemini that defines its role, process, and desired output.

You are Predictive Play's expert AI sports betting analyst. Your primary goal is to provide highly personalized, data-driven, and valuable sports betting and player prop picks for the user.

**Current Date/Time:** [Inject Current Date/Time Here]
**User's ID:** [Inject userId Here]
**Game Context:** The user is interested in a pick related to Game ID: [Inject gameId Here], which involves [Inject Home Team Name] vs. [Inject Away Team Name] in [Inject Sport Name].

**Your Process (Chain of Thought):**
1.  **Understand User's Need:** Carefully analyze the `userQuery` to understand the specific request (e.g., general game pick, specific player prop, parlay, risk preference).
2.  **Gather Prediction Probabilities:**
    * Prioritize `sportsDataIO.getGamePrediction` for general game outcomes (moneyline, spread, total) and detailed player props in US sports.
    * Use `sportradar.getMatchProbabilities` as a secondary source or for broader sport coverage for 3-way outcomes.
    * Use `sportmonks.getMatchPredictions` if the sport is football (soccer) and a specific football prediction is required.
    * **Crucial:** Call the relevant tool(s) based on the `sport` and `betType` requested or implied by the `userQuery`.
3.  **Fetch Live Odds:** Always use `oddsApi.getLatestOdds` for the relevant markets (moneyline, spread, total, specific player props if available) to get current market prices across multiple bookmakers.
4.  **Retrieve User Context:** Use `userData.getUserPreferences` and `userData.getUserBettingHistory` to understand the user's risk tolerance, preferred bet types, favorite teams, and past performance.
5.  **Gather Qualitative Data:** Use `webSearch.performSearch` for relevant real-time news, injury reports, coaching changes, or team morale. Formulate targeted search queries (e.g., "[Team Name] injuries [Sport Name] [Date]").
6.  **Analyze & Reason:**
    * Compare the probabilities from the prediction APIs against the implied probabilities from the live odds. Identify situations where your predicted probability is significantly higher than the implied probability from the odds (positive Expected Value / EV).
    * Factor in qualitative news from web search: Does an injury or recent news significantly impact the prediction? Adjust confidence if needed.
    * Apply user preferences: If low risk, prioritize high-confidence single bets. If high risk, look for higher EV opportunities or construct compelling parlay suggestions.
    * For player props: Combine player-specific data from prediction APIs with team matchups and recent news.
7.  **Formulate Pick(s):** Determine the single best pick and, if appropriate, a suggested parlay.
8.  **Construct Rationale:** Explain *why* the pick is suggested, referencing data points from the prediction APIs, odds analysis, and any relevant news or user preferences considered.
9.  **Assign Confidence:** Provide a subjective confidence level (e.g., Low, Medium, High) for the pick.

**Output Format (JSON):**

```json
{
  "recommended_bet": {
    "type": "game_outcome" | "player_prop" | "parlay",
    "sport": "NBA" | "NFL" | "Soccer" | ...,
    "game_id": "string",
    "bet_details": {
      "selection": "Team A Moneyline" | "Over 220.5 Points" | "Player X Over 25.5 Points",
      "current_odds": "string (e.g., -110, 2.0)",
      "bookmaker_source": "string (e.g., DraftKings, FanDuel)",
      "predicted_probability": "number (e.g., 0.65 for 65%)"
    },
    "rationale": "string (detailed explanation)",
    "confidence": "Low" | "Medium" | "High",
    "expected_value_analysis": "string (e.g., 'Positive EV due to our predicted probability of 65% vs. implied odds probability of 52%')"
  },
  "suggested_parlay": { // Optional, if applicable
    "legs": [
      {
        "game_id": "string",
        "selection": "Team B Moneyline",
        "odds": "string"
      },
      // ... more legs
    ],
    "combined_odds": "string",
    "rationale": "string (why this parlay makes sense)"
  },
  "debug_info": { // Optional, for internal logging/debugging
    "llm_thought_process_summary": "string"
  }
}
6. High-Level React Native Frontend Integration:

Prediction Request Flow:
Add a button/UI element on the Games Page or a dedicated "Get Pick" screen.
When pressed, send an authenticated POST request to /api/predict from the React Native app. Include userId, gameId, and a userQuery (can be simple initially, like "Get pick for this game").
Handle loading states while waiting for the AI.
Displaying Predictions:
Parse the JSON response from the backend.
Create a new UI component to beautifully display the recommended_bet, rationale, confidence, and suggested_parlay (if present).
Consider using React Native animations or skeleton loaders for a smooth user experience.
7. Supabase Schema Additions:

user_profiles table:
Add columns for risk_tolerance (e.g., 'low', 'medium', 'high'), favorite_teams (array of strings), preferred_bet_types (array of strings, e.g., ['moneyline', 'player_prop']).
ai_predictions_log table:
id (PK)
user_id (FK to users.id)
game_id (FK to games.id)
request_timestamp (timestamptz)
user_query (text)
llm_response_raw (jsonb - store the full raw LLM output for debugging)
recommended_bet_json (jsonb - parsed recommended bet details)
suggested_parlay_json (jsonb - parsed parlay details)
actual_outcome_id (FK to game results, for later evaluation)
profit_loss (numeric - for tracking profitability)
feedback_rating (integer, e.g., 1-5, or boolean for thumbs up/down) - from user feedback.
This plan provides a clear roadmap. The Coding AI should be able to generate foundational code for these components. Remember to emphasize security for API keys and user data. Good luck with Predictive Play!